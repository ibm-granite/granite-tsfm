# Copyright contributors to the TSFM project

# Portions of this Dockerfile are taken from
# https://gitlab.com/nvidia/container-images
# Copyright (c) 2019,2020,2021 NVIDIA CORPORATION. All rights reserved.

FROM tsfminference-cpu AS base

USER root

ARG PYTHON_VERSION=3.12
ENV NVARCH="x86_64"
ENV NVIDIA_REQUIRE_CUDA="cuda>=12.4 brand=tesla,driver>=470,driver<471 brand=unknown,driver>=470,driver<471 brand=nvidia,driver>=470,driver<471 brand=nvidiartx,driver>=470,driver<471 brand=geforce,driver>=470,driver<471 brand=geforcertx,driver>=470,driver<471 brand=quadro,driver>=470,driver<471 brand=quadrortx,driver>=470,driver<471 brand=titan,driver>=470,driver<471 brand=titanrtx,driver>=470,driver<471 brand=tesla,driver>=525,driver<526 brand=unknown,driver>=525,driver<526 brand=nvidia,driver>=525,driver<526 brand=nvidiartx,driver>=525,driver<526 brand=geforce,driver>=525,driver<526 brand=geforcertx,driver>=525,driver<526 brand=quadro,driver>=525,driver<526 brand=quadrortx,driver>=525,driver<526 brand=titan,driver>=525,driver<526 brand=titanrtx,driver>=525,driver<526 brand=tesla,driver>=535,driver<536 brand=unknown,driver>=535,driver<536 brand=nvidia,driver>=535,driver<536 brand=nvidiartx,driver>=535,driver<536 brand=geforce,driver>=535,driver<536 brand=geforcertx,driver>=535,driver<536 brand=quadro,driver>=535,driver<536 brand=quadrortx,driver>=535,driver<536 brand=titan,driver>=535,driver<536 brand=titanrtx,driver>=535,driver<536"
# ENV NV_CUDA_CUDART_VERSION="12.4.127-1"
COPY cuda.repo-x86_64 /etc/yum.repos.d/cuda.repo
RUN NVIDIA_GPGKEY_SUM=d0664fbbdb8c32356d45de36c5984617217b2d0bef41b93ccecd326ba3b80c87 && \
    curl -fsSL https://developer.download.nvidia.com/compute/cuda/repos/rhel9/${NVARCH}/D42D0685.pub | sed '/^Version/d' > /etc/pki/rpm-gpg/RPM-GPG-KEY-NVIDIA && \
    echo "$NVIDIA_GPGKEY_SUM  /etc/pki/rpm-gpg/RPM-GPG-KEY-NVIDIA" | sha256sum -c --strict -

# See https://developer.download.nvidia.com/compute/cuda/repos/rhel9/x86_64/
ENV NV_CUDA_VERSION="12-6"
ENV LIB_NCCL_VERSION="2.24.3"
ENV LIB_CUDNN_VERSION="13-9.14.0.64"

RUN microdnf install -y yum && yum install -y \
    cuda-cudart-${NV_CUDA_VERSION} \
    cuda-compat-${NV_CUDA_VERSION} \
    cuda-libraries-${NV_CUDA_VERSION} \
    cuda-nvtx-${NV_CUDA_VERSION} \
    libnpp-${NV_CUDA_VERSION} \
    libcublas-${NV_CUDA_VERSION} \
    libnccl-${LIB_NCCL_VERSION} \
    libcudnn9-cuda-${LIB_CUDNN_VERSION} \
    && yum clean all \
    && microdnf clean all \
    && rm -rf /var/cache/yum/*

# nvidia-docker 1.0
RUN echo "/usr/local/nvidia/lib" >> /etc/ld.so.conf.d/nvidia.conf && \
    echo "/usr/local/nvidia/lib64" >> /etc/ld.so.conf.d/nvidia.conf

ENV PATH=/usr/local/nvidia/bin:/usr/local/cuda/bin:${PATH}
ENV LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64

# nvidia-container-runtime
ENV NVIDIA_VISIBLE_DEVICES=all
ENV NVIDIA_DRIVER_CAPABILITIES="compute,utility"

FROM base AS runtime-base

USER tsfm
# get back our gpu-enabled version of torch and all the nvidia packages
RUN  uv sync --locked
ENV LD_LIBRARY_PATH=${HOME}/.venv/lib/python${PYTHON_VERSION}/site-packages/nvidia/cuda_cupti/lib:${HOME}/.venv/lib//lib/python${PYTHON_VERSION}/site-packages/nvidia/cuda_cupti/lib:${HOME}/.venv/lib//lib/python${PYTHON_VERSION}/site-packages/cusparselt/lib/:${LD_LIBRARY_PATH}

ENV CUDA_VISIBLE_DEVICES=0
HEALTHCHECK CMD curl --fail http://localhost:8000/healthcheck || exit 1

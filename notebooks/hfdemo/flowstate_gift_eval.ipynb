{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "088e8ecf",
   "metadata": {},
   "source": [
    "# Running Gift-Eval with FlowState"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324acc12",
   "metadata": {},
   "source": [
    "This notebook demonstrate how to evaluate FlowState on the [Gift-Eval Benchmark](https://huggingface.co/spaces/Salesforce/GIFT-Eval)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aabf2bf",
   "metadata": {},
   "source": [
    "### Preparing the experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e384d2",
   "metadata": {},
   "source": [
    "To get started, please follow the installation instructions from [here](https://github.com/ibm-granite/granite-tsfm/?tab=readme-ov-file#initial-setup).\n",
    "Moreover, you need to install the gift_eval package, which can be done by following the instructions from [here](https://github.com/SalesforceAIResearch/gift-eval?tab=readme-ov-file#installation)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682aca15",
   "metadata": {},
   "source": [
    "Import the necessary third-party dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28e43ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from gift_eval.data import Dataset\n",
    "from gluonts.ev.metrics import (\n",
    "    MAE,\n",
    "    MAPE,\n",
    "    MASE,\n",
    "    MSE,\n",
    "    MSIS,\n",
    "    ND,\n",
    "    NRMSE,\n",
    "    RMSE,\n",
    "    SMAPE,\n",
    "    MeanWeightedSumQuantileLoss,\n",
    ")\n",
    "from gluonts.model import evaluate_model\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a802a7e",
   "metadata": {},
   "source": [
    "Import the FlowState model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f0c3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flowstate.gift_wrapper import FlowState_Gift_Wrapper\n",
    "\n",
    "from tsfm_public import FlowStateForPrediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bfcb79",
   "metadata": {},
   "source": [
    "Prepare the configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f987838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path configurations\n",
    "out_dir = \"./results\"\n",
    "dataset_properties = \"./flowstate/dataset_properties.json\"\n",
    "\n",
    "# Model configurations\n",
    "model_name = \"ibm-granite/granite-timeseries-flowstate-r1\"\n",
    "\n",
    "# Auxiliary configurations\n",
    "seed = 0\n",
    "device = \"cuda\"\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a02f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment configurations\n",
    "short_datasets = \"m4_yearly m4_quarterly m4_monthly m4_weekly m4_daily m4_hourly electricity/15T electricity/H electricity/D electricity/W solar/10T solar/H solar/D solar/W hospital covid_deaths us_births/D us_births/M us_births/W saugeenday/D saugeenday/M saugeenday/W temperature_rain_with_missing kdd_cup_2018_with_missing/H kdd_cup_2018_with_missing/D car_parts_with_missing restaurant hierarchical_sales/D hierarchical_sales/W LOOP_SEATTLE/5T LOOP_SEATTLE/H LOOP_SEATTLE/D SZ_TAXI/15T SZ_TAXI/H M_DENSE/H M_DENSE/D ett1/15T ett1/H ett1/D ett1/W ett2/15T ett2/H ett2/D ett2/W jena_weather/10T jena_weather/H jena_weather/D bitbrains_fast_storage/5T bitbrains_fast_storage/H bitbrains_rnd/5T bitbrains_rnd/H bizitobs_application bizitobs_service bizitobs_l2c/5T bizitobs_l2c/H\"\n",
    "med_long_datasets = \"electricity/15T electricity/H solar/10T solar/H kdd_cup_2018_with_missing/H LOOP_SEATTLE/5T LOOP_SEATTLE/H SZ_TAXI/15T M_DENSE/H ett1/15T ett1/H ett2/15T ett2/H jena_weather/10T jena_weather/H bitbrains_fast_storage/5T bitbrains_rnd/5T bizitobs_application bizitobs_service bizitobs_l2c/5T bizitobs_l2c/H\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c29637e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary functions\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def LoadFlowState(pred_length, n_ch, freq, device=\"cpu\", domain=None, nd=False):\n",
    "    flowstate = FlowStateForPrediction.from_pretrained(model_name).to(device)\n",
    "    config = flowstate.config\n",
    "    config.min_context = 0\n",
    "    flowstate = FlowState_Gift_Wrapper(\n",
    "        flowstate, pred_length, n_ch=n_ch, batch_size=batch_size, f=freq, device=device, domain=domain, no_daily=nd\n",
    "    )\n",
    "    return flowstate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e9a469",
   "metadata": {},
   "source": [
    "Experiment wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4b0470",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_row = [\n",
    "    \"dataset\",\n",
    "    \"model\",\n",
    "    \"eval_metrics/MSE[mean]\",\n",
    "    \"eval_metrics/MSE[0.5]\",\n",
    "    \"eval_metrics/MAE[mean]\",\n",
    "    \"eval_metrics/MAE[0.5]\",\n",
    "    \"eval_metrics/MASE[0.5]\",\n",
    "    \"eval_metrics/MAPE[0.5]\",\n",
    "    \"eval_metrics/sMAPE[0.5]\",\n",
    "    \"eval_metrics/MSIS\",\n",
    "    \"eval_metrics/RMSE[mean]\",\n",
    "    \"eval_metrics/NRMSE[mean]\",\n",
    "    \"eval_metrics/ND[0.5]\",\n",
    "    \"eval_metrics/mean_weighted_sum_quantile_loss\",\n",
    "    \"domain\",\n",
    "    \"num_variates\",\n",
    "]\n",
    "\n",
    "\n",
    "def run_gift_eval(zs=False, save=False, verbose=True):\n",
    "    set_seed(seed)\n",
    "\n",
    "    # Get union of short and med_long datasets\n",
    "    all_datasets = sorted(set(short_datasets.split() + med_long_datasets.split()))\n",
    "    dataset_properties_map = json.load(open(dataset_properties))\n",
    "\n",
    "    # Instantiate the metrics\n",
    "    metrics = [\n",
    "        MSE(forecast_type=\"mean\"),\n",
    "        MSE(forecast_type=0.5),\n",
    "        MAE(forecast_type=\"mean\"),\n",
    "        MAE(forecast_type=0.5),\n",
    "        MASE(),\n",
    "        MAPE(),\n",
    "        SMAPE(),\n",
    "        MSIS(),\n",
    "        RMSE(),\n",
    "        NRMSE(),\n",
    "        ND(),\n",
    "        MeanWeightedSumQuantileLoss(quantile_levels=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]),\n",
    "    ]\n",
    "\n",
    "    # ## Evaluation\n",
    "    # Define the path for the CSV file\n",
    "    csv_file_path = os.path.join(out_dir, \"gift_eval\", f\"{model_name}_all_results.csv\")\n",
    "\n",
    "    pretty_names = {\n",
    "        \"saugeenday\": \"saugeen\",\n",
    "        \"temperature_rain_with_missing\": \"temperature_rain\",\n",
    "        \"kdd_cup_2018_with_missing\": \"kdd_cup_2018\",\n",
    "        \"car_parts_with_missing\": \"car_parts\",\n",
    "    }\n",
    "\n",
    "    if not os.path.exists(csv_file_path) and save:\n",
    "        with open(csv_file_path, \"a\", newline=\"\") as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "\n",
    "            # Write the header\n",
    "            writer.writerow(base_row)\n",
    "    if save:\n",
    "        df_res_done = pd.read_csv(csv_file_path)\n",
    "        done_datasets = df_res_done[\"dataset\"].values\n",
    "    else:\n",
    "        done_datasets = []\n",
    "    df_res = pd.DataFrame(columns=base_row)\n",
    "    if verbose:\n",
    "        print(\"Done datasets\")\n",
    "        print(done_datasets)\n",
    "\n",
    "    if zs:  # the zero-shot subset whithout data leakage for the chronos pretraining corpus (to fairly compare with tirex and chronos models)\n",
    "        excluded = [\n",
    "            \"solar/H\",\n",
    "            \"m4_monthly\",\n",
    "            \"m4_weekly\",\n",
    "            \"m4_daily\",\n",
    "            \"m4_hourly\",\n",
    "            \"electricity/15T\",\n",
    "            \"electricity/H\",\n",
    "            \"electricity/W\",\n",
    "            \"kdd_cup_2018_with_missing/D\",\n",
    "            \"kdd_cup_2018_with_missing/H\",\n",
    "            \"temperature_rain_with_missing\",\n",
    "        ]\n",
    "    else:\n",
    "        excluded = []\n",
    "\n",
    "    for ds_name in all_datasets:\n",
    "        if ds_name in excluded:\n",
    "            continue\n",
    "        set_seed(seed)\n",
    "        terms = [\"short\", \"medium\", \"long\"]\n",
    "        # terms = [\"short\"]\n",
    "        # terms = [\"medium\", \"long\"]\n",
    "        for term in terms:\n",
    "            if (term == \"medium\" or term == \"long\") and ds_name not in med_long_datasets.split():\n",
    "                continue\n",
    "            if verbose:\n",
    "                print(f\"Processing dataset: {ds_name}, term: {term}\")\n",
    "\n",
    "            if \"/\" in ds_name:\n",
    "                ds_key = ds_name.split(\"/\")[0]\n",
    "                ds_freq = ds_name.split(\"/\")[1]\n",
    "                ds_key = ds_key.lower()\n",
    "                ds_key = pretty_names.get(ds_key, ds_key)\n",
    "            else:\n",
    "                ds_key = ds_name.lower()\n",
    "                ds_key = pretty_names.get(ds_key, ds_key)\n",
    "                ds_freq = dataset_properties_map[ds_key][\"frequency\"]\n",
    "            ds_config = f\"{ds_key}/{ds_freq}/{term}\"\n",
    "\n",
    "            to_univariate = False if Dataset(name=ds_name, term=term, to_univariate=False).target_dim == 1 else True\n",
    "            dataset = Dataset(name=ds_name, term=term, to_univariate=to_univariate)\n",
    "\n",
    "            all_lengths = []\n",
    "            for x in dataset.test_data:\n",
    "                if len(x[0][\"target\"].shape) == 1:\n",
    "                    all_lengths.append(len(x[0][\"target\"]))\n",
    "                    num_channels = 1\n",
    "                else:\n",
    "                    all_lengths.append(x[0][\"target\"].shape[1])\n",
    "                    num_channels = x[0][\"target\"].shape[0]\n",
    "\n",
    "            if ds_config in done_datasets:\n",
    "                if verbose:\n",
    "                    print(f\"Done with {ds_config}. Skipping...\")\n",
    "                df_res = df_res._append(df_res_done.loc[df_res_done[\"dataset\"] == ds_config], ignore_index=True)\n",
    "                continue\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"Dataset: {ds_name}, Freq = {dataset.freq}, H = {dataset.prediction_length}\")\n",
    "\n",
    "            no_daily = (\n",
    "                \"l2c\" in ds_name\n",
    "            )  # necessary to get correct seasonality for bizitobs_l2c datasets (which have no daily cycles)\n",
    "            flowstate = LoadFlowState(\n",
    "                pred_length=dataset.prediction_length,\n",
    "                n_ch=num_channels,\n",
    "                freq=dataset.freq,\n",
    "                device=device,\n",
    "                domain=dataset_properties_map[ds_key][\"domain\"],\n",
    "                nd=no_daily,\n",
    "            )\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"Number of channels in the dataset {ds_name} =\", num_channels)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # Evaluate\n",
    "                res = evaluate_model(\n",
    "                    flowstate,\n",
    "                    test_data=dataset.test_data,\n",
    "                    metrics=metrics,\n",
    "                    batch_size=batch_size,\n",
    "                    axis=None,\n",
    "                    mask_invalid_label=True,\n",
    "                    allow_nan_forecast=False,\n",
    "                    # seasonality=season_length,\n",
    "                )\n",
    "            if verbose:\n",
    "                print(f\"MASE: {res['MASE[0.5]'][0]}\")\n",
    "            # Append the results to the CSV file\n",
    "            row = [\n",
    "                ds_config,\n",
    "                model_name,\n",
    "                res[\"MSE[mean]\"][0],\n",
    "                res[\"MSE[0.5]\"][0],\n",
    "                res[\"MAE[mean]\"][0],\n",
    "                res[\"MAE[0.5]\"][0],\n",
    "                res[\"MASE[0.5]\"][0],\n",
    "                res[\"MAPE[0.5]\"][0],\n",
    "                res[\"sMAPE[0.5]\"][0],\n",
    "                res[\"MSIS\"][0],\n",
    "                res[\"RMSE[mean]\"][0],\n",
    "                res[\"NRMSE[mean]\"][0],\n",
    "                res[\"ND[0.5]\"][0],\n",
    "                res[\"mean_weighted_sum_quantile_loss\"][0],\n",
    "                dataset_properties_map[ds_key][\"domain\"],\n",
    "                dataset_properties_map[ds_key][\"num_variates\"],\n",
    "            ]\n",
    "            if save:\n",
    "                with open(csv_file_path, \"a\", newline=\"\") as csvfile:\n",
    "                    writer = csv.writer(csvfile)\n",
    "                    writer.writerow(row)\n",
    "                if verbose:\n",
    "                    print(f\"Results for {ds_name} have been written to {csv_file_path}\")\n",
    "            df_res.loc[len(df_res)] = row\n",
    "\n",
    "    # Print Results\n",
    "    seasonal_naive = pd.read_csv(\"results/baselines/Seasonal_Naive.csv\").sort_values(\"dataset\")\n",
    "    dataset = seasonal_naive[\"dataset\"].to_list()\n",
    "    seasonal_naive_mase = seasonal_naive[\"eval_metrics/MASE[0.5]\"].to_numpy()\n",
    "    seasonal_naive_crps = seasonal_naive[\"eval_metrics/mean_weighted_sum_quantile_loss\"].to_numpy()\n",
    "    df = df_res\n",
    "    df = df.sort_values(by=\"dataset\")\n",
    "    df[\"normalized MASE\"] = np.zeros(len(df))\n",
    "    df[\"normalized CRPS\"] = np.zeros(len(df))\n",
    "    df[\"freq\"] = np.zeros(len(df))\n",
    "    df[\"len\"] = np.zeros(len(df))\n",
    "    for ds in df[\"dataset\"]:\n",
    "        idx = dataset.index(ds)\n",
    "        _, f, l = ds.split(\"/\")\n",
    "        df.loc[df[\"dataset\"] == ds, \"freq\"] = f\n",
    "        df.loc[df[\"dataset\"] == ds, \"len\"] = l\n",
    "        df.loc[df[\"dataset\"] == ds, \"normalized MASE\"] = (\n",
    "            df.loc[df[\"dataset\"] == ds, \"eval_metrics/MASE[0.5]\"].values / seasonal_naive_mase[idx]\n",
    "        )\n",
    "        df.loc[df[\"dataset\"] == ds, \"normalized CRPS\"] = (\n",
    "            df.loc[df[\"dataset\"] == ds, \"eval_metrics/mean_weighted_sum_quantile_loss\"].values\n",
    "            / seasonal_naive_crps[idx]\n",
    "        )\n",
    "\n",
    "    df = df.sort_values(by=[\"dataset\"])\n",
    "\n",
    "    def geo_mean(iterable):\n",
    "        a = np.array(iterable)\n",
    "        return a.prod() ** (1.0 / len(a))\n",
    "\n",
    "    mase = geo_mean(df[\"normalized MASE\"].to_numpy())\n",
    "    crps = geo_mean(df[\"normalized CRPS\"].to_numpy())\n",
    "    if verbose:\n",
    "        print(\n",
    "            df[\n",
    "                [\n",
    "                    \"dataset\",\n",
    "                    \"freq\",\n",
    "                    \"eval_metrics/MASE[0.5]\",\n",
    "                    \"eval_metrics/mean_weighted_sum_quantile_loss\",\n",
    "                    \"normalized MASE\",\n",
    "                    \"normalized CRPS\",\n",
    "                ]\n",
    "            ].to_markdown()\n",
    "        )\n",
    "\n",
    "    return mase, crps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59132bc",
   "metadata": {},
   "source": [
    "Start the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f29951d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mase, crps = run_gift_eval(verbose=True, zs=False, save=False)\n",
    "print(f\"Final GIFT-Eval Performance of {model_name}:\\nMASE = {mase}, CRPS = {crps}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "granite_tsfm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
